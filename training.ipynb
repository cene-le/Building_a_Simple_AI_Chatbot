{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "251b8d79-12b0-43d2-96bf-73115568e382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached numpy-1.26.3-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.26.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# install the library\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3775a15-dc19-46f7-9783-2d7d68a45d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Collecting click\n",
      "  Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Collecting regex>=2021.8.3\n",
      "  Using cached regex-2023.12.25-cp310-cp310-win_amd64.whl (269 kB)\n",
      "Collecting colorama\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: regex, joblib, colorama, tqdm, click, nltk\n",
      "Successfully installed click-8.1.7 colorama-0.4.6 joblib-1.3.2 nltk-3.8.1 regex-2023.12.25 tqdm-4.66.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3da8d4d-b112-47b0-9a75-ba8b4a97328e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached tensorflow-2.15.0-cp310-cp310-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.15.0\n",
      "  Using cached tensorflow_intel-2.15.0-cp310-cp310-win_amd64.whl (300.9 MB)\n",
      "Collecting keras<2.16,>=2.15.0\n",
      "  Using cached keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "     ---------------------------------------- 0.0/133.7 kB ? eta -:--:--\n",
      "     -------------------------------------  133.1/133.7 kB 4.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- 133.7/133.7 kB 4.0 MB/s eta 0:00:00\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.25.2-cp310-abi3-win_amd64.whl (413 kB)\n",
      "     ---------------------------------------- 0.0/413.4 kB ? eta -:--:--\n",
      "     ----------------- -------------------- 194.6/413.4 kB 3.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- 413.4/413.4 kB 4.3 MB/s eta 0:00:00\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting wrapt<1.15,>=1.11.0\n",
      "  Using cached wrapt-1.14.1-cp310-cp310-win_amd64.whl (35 kB)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0\n",
      "  Using cached tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "Collecting six>=1.12.0\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting tensorboard<2.16,>=2.15\n",
      "  Using cached tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenovo\\chatbot\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (65.5.0)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.60.0-cp310-cp310-win_amd64.whl (3.7 MB)\n",
      "Collecting flatbuffers>=23.5.26\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Using cached gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Using cached typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Using cached h5py-3.10.0-cp310-cp310-win_amd64.whl (2.7 MB)\n",
      "Collecting ml-dtypes~=0.2.0\n",
      "  Using cached ml_dtypes-0.2.0-cp310-cp310-win_amd64.whl (938 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\lenovo\\chatbot\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.26.3)\n",
      "Collecting packaging\n",
      "  Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Using cached wheel-0.42.0-py3-none-any.whl (65 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.27.0-py2.py3-none-any.whl (186 kB)\n",
      "     ---------------------------------------- 0.0/186.8 kB ? eta -:--:--\n",
      "     -------------------------------------- 186.8/186.8 kB 5.7 MB/s eta 0:00:00\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.5.2-py3-none-any.whl (103 kB)\n",
      "     ---------------------------------------- 0.0/103.9 kB ? eta -:--:--\n",
      "     -------------------------------------- 103.9/103.9 kB 5.9 MB/s eta 0:00:00\n",
      "Collecting google-auth-oauthlib<2,>=0.5\n",
      "  Using cached google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Using cached protobuf-4.23.4-cp310-abi3-win_amd64.whl (422 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.6-py3-none-any.whl (61 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.3.2-cp310-cp310-win_amd64.whl (100 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.4-cp310-cp310-win_amd64.whl (17 kB)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Using cached pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, six, pyasn1, protobuf, packaging, opt-einsum, oauthlib, ml-dtypes, MarkupSafe, markdown, keras, idna, h5py, grpcio, gast, charset-normalizer, certifi, cachetools, absl-py, werkzeug, rsa, requests, pyasn1-modules, google-pasta, astunparse, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "Successfully installed MarkupSafe-2.1.4 absl-py-2.1.0 astunparse-1.6.3 cachetools-5.3.2 certifi-2023.11.17 charset-normalizer-3.3.2 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.27.0 google-auth-oauthlib-1.2.0 google-pasta-0.2.0 grpcio-1.60.0 h5py-3.10.0 idna-3.6 keras-2.15.0 libclang-16.0.6 markdown-3.5.2 ml-dtypes-0.2.0 oauthlib-3.2.2 opt-einsum-3.3.0 packaging-23.2 protobuf-4.23.4 pyasn1-0.5.1 pyasn1-modules-0.3.0 requests-2.31.0 requests-oauthlib-1.3.1 rsa-4.9 six-1.16.0 tensorboard-2.15.1 tensorboard-data-server-0.7.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-intel-2.15.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0 typing-extensions-4.9.0 urllib3-2.1.0 werkzeug-3.0.1 wheel-0.42.0 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49645d4-9e6a-4ff5-89f2-4ed2eb85cb2e",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53077b5b-b8de-431e-a666-21fde9540363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81b3b96-b45d-430c-ba2f-8aa2c6d10f56",
   "metadata": {},
   "source": [
    "## Read Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b2ad39e-a775-48f4-94c1-5d294c76abd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Fungsi untuk membaca data intents dari file JSON\n",
    "def load_intents_from_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        intents_data = json.load(file)\n",
    "    return intents_data\n",
    "\n",
    "# Menentukan path file intents.json\n",
    "intents_file_path = 'intents.json'\n",
    "\n",
    "# Memuat data intents dari file JSON\n",
    "intents = load_intents_from_json(intents_file_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c41395cb-8b17-410f-bfdb-193cba0e9cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"intents\": [\n",
      "    {\n",
      "      \"tag\": \"greeting\",\n",
      "      \"patterns\": [\n",
      "        \"Hello\",\n",
      "        \"Hi\",\n",
      "        \"Halo\",\n",
      "        \"Hai\",\n",
      "        \"Magandang umaga\",\n",
      "        \"Kamusta\",\n",
      "        \"Magandang hapon\",\n",
      "        \"Magandang gabi\"\n",
      "      ],\n",
      "      \"responses\": [\n",
      "        \"Hello! Welcome to FashionFusion. I can help you find the perfect outfit. Is there anything specific you're looking for?\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"tag\": \"StockItems\",\n",
      "      \"patterns\": [\n",
      "        \"I want to know what stock of clothes is available right now\",\n",
      "        \"what are the popular types of clothing currently?\",\n",
      "        \"I am looking for popular clothing now, what do you recommend?\",\n",
      "        \"can you give me a list of best-selling products?\"\n",
      "      ],\n",
      "      \"responses\": [\n",
      "        \"We have a variety of trendy clothes available right now, including floral dresses, oversized shirts, and denim jackets. To view the catalog please visit FashionFusion.com.\",\n",
      "        \"In our collection, you will find a variety of interesting choices, from casual to formal. Please visit FashionFusion.com for more details.\",\n",
      "        \"Currently, our most popular collection is spring clothes with bright colors. You can explore these choices at FashionFusion.com\",\n",
      "        \"Of course! We have various popular options, including graphic t-shirts, chino pants, and accessories. You can explore these choices at FashionFusion.com\",\n",
      "        \"We always update our stock with the latest trends. Currently, we have a special summer collection with special discounts. Are you interested?\",\n",
      "        \"For a complete collection of items we sell, you can visit FashionFusion.com. There, you can choose based on category, size, and color.\",\n",
      "        \"We are happy to provide recommendations! For a casual look, we recommend our comfortable plain t-shirts. For formal events, maybe you are interested in our blazer collection.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"tag\": \"PriceRange\",\n",
      "      \"patterns\": [\n",
      "        \"what is the price range of clothes sold\",\n",
      "        \"how much is the price range sold\",\n",
      "        \"is it expensive?\",\n",
      "        \"what is the average price for clothes here?\",\n",
      "        \"are there affordable clothes?\"\n",
      "      ],\n",
      "      \"responses\": [\n",
      "        \"We offer a variety of choices with a varied price range, starting from 100 thousand to 1 million rupiah, depending on the style and material.\",\n",
      "        \"Our prices are competitive and match the quality we offer. You can get good clothes with prices starting from 200 thousand rupiah.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"tag\": \"OrderingMethod\",\n",
      "      \"patterns\": [\n",
      "        \"How do I order clothes?\",\n",
      "        \"What is the online ordering procedure?\"\n",
      "      ],\n",
      "      \"responses\": [\n",
      "        \"You can order directly through our website at FashionFusion.com. Choose the clothes you want, add them to the cart, and follow the checkout process.\",\n",
      "        \"Online ordering is very easy. Visit FashionFusion.com, choose a product, and make the payment.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"tag\": \"Closing\",\n",
      "      \"patterns\": [\n",
      "        \"Thank you for the information.\",\n",
      "        \"I will check the website.\",\n",
      "        \"Okay, that's all I need.\"\n",
      "      ],\n",
      "      \"responses\": [\n",
      "        \"You're welcome, glad to help. Happy shopping!\",\n",
      "        \"Please, visit our website for more collections. If you have any other questions, we are ready to help.\",\n",
      "        \"Alright, if there is anything else you need, don't hesitate to contact us. Happy shopping!\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(intents, indent=2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c965b462-1eb4-4780-83b7-ee8d05f1b26c",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d1f3007-17ae-4f99-875a-47d7ae1a9af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "intents = json.loads(open('intents.json').read())     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7c3baf1-8e26-40a3-9332-27faf3ec747d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word list after preprocessing:\n",
      "['a', 'affordable', 'all', 'am', 'are', 'available', 'average', 'best-selling', 'can', 'check', 'clothes', 'clothing', 'currently', 'do', 'expensive', 'for', 'gabi', 'give', 'hai', 'halo', 'hapon', 'hello', 'here', 'hi', 'how', 'i', 'information', 'is', 'it', 'kamusta', 'know', 'list', 'looking', 'magandang', 'me', 'much', 'need', 'now', 'of', 'okay', 'online', 'order', 'ordering', 'popular', 'price', 'procedure', 'product', 'range', 'recommend', 'right', 'sold', 'stock', 'thank', 'that', 'the', 'there', 'to', 'type', 'umaga', 'want', 'website', 'what', 'will', 'you']\n",
      "Number of tokens generated: 64\n",
      "Number of tags generated: 5\n"
     ]
    }
   ],
   "source": [
    "#tokenization and corpus formation\n",
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_latters = \"?!.,/'\"\n",
    "\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        word_list = nltk.word_tokenize(pattern)\n",
    "        words.extend(word_list)\n",
    "        documents.append((word_list, intent['tag']))\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])\n",
    "\n",
    "words = [lemmatizer.lemmatize(word) for word in words if word not in ignore_latters]\n",
    "words = [word.lower() for word in words if word not in ignore_latters]\n",
    "words = sorted(set(words))\n",
    "print(\"Word list after preprocessing:\")\n",
    "print(words)\n",
    "\n",
    "print(\"Number of tokens generated:\", len(words)) \n",
    "print(\"Number of tags generated:\", len(classes))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd71016a-6c5f-4385-afb7-d5a4461680dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation and saving of pixel models using the pickle module.\n",
    "pickle.dump(words, open('words.pkl', 'wb'))\n",
    "pickle.dump(classes, open('classes.pkl', 'wb')) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103b293f-73d4-4e92-8aa5-1389d5dc046f",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d09c6f3-88ac-4ff4-9f70-99149200428d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "4/4 [==============================] - 2s 97ms/step - loss: 1.6039 - accuracy: 0.2353 - val_loss: 1.7018 - val_accuracy: 0.2000\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.4681 - accuracy: 0.5882 - val_loss: 1.6415 - val_accuracy: 0.4000\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.2336 - accuracy: 0.4706 - val_loss: 1.3909 - val_accuracy: 0.6000\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7714 - accuracy: 0.7647 - val_loss: 1.2511 - val_accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7014 - accuracy: 0.7059 - val_loss: 1.3957 - val_accuracy: 0.6000\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5312 - accuracy: 0.8235 - val_loss: 1.3599 - val_accuracy: 0.6000\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6116 - accuracy: 0.7647 - val_loss: 1.5921 - val_accuracy: 0.6000\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2902 - accuracy: 0.9412 - val_loss: 1.6475 - val_accuracy: 0.6000\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3408 - accuracy: 0.8235 - val_loss: 1.3256 - val_accuracy: 0.6000\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2608 - accuracy: 0.9412 - val_loss: 1.3697 - val_accuracy: 0.6000\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2717 - accuracy: 0.9412 - val_loss: 1.2142 - val_accuracy: 0.6000\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1348 - accuracy: 0.9412 - val_loss: 1.3247 - val_accuracy: 0.6000\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1098 - accuracy: 0.9412 - val_loss: 1.4466 - val_accuracy: 0.6000\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2607 - accuracy: 0.9412 - val_loss: 1.4954 - val_accuracy: 0.6000\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1951 - accuracy: 0.9412 - val_loss: 1.5861 - val_accuracy: 0.6000\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0953 - accuracy: 0.9412 - val_loss: 1.4277 - val_accuracy: 0.6000\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0566 - accuracy: 1.0000 - val_loss: 1.5478 - val_accuracy: 0.6000\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0481 - accuracy: 1.0000 - val_loss: 1.3627 - val_accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.2651 - val_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 1.1783 - val_accuracy: 0.8000\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.3948 - val_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 1.5137 - val_accuracy: 0.8000\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 1.5268 - val_accuracy: 0.6000\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0538 - accuracy: 1.0000 - val_loss: 1.8698 - val_accuracy: 0.6000\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 1.8969 - val_accuracy: 0.6000\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 1.5045 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.4722 - val_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 7.2413e-04 - accuracy: 1.0000 - val_loss: 1.4981 - val_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.6300e-04 - accuracy: 1.0000 - val_loss: 1.4961 - val_accuracy: 0.8000\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.6320 - val_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 1.8096 - val_accuracy: 0.8000\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.8663 - val_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.8923 - val_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.9318e-04 - accuracy: 1.0000 - val_loss: 1.8473 - val_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.9964 - val_accuracy: 0.8000\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.3692 - val_accuracy: 0.6000\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.3675e-04 - accuracy: 1.0000 - val_loss: 2.3947 - val_accuracy: 0.6000\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.0343 - val_accuracy: 0.6000\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 1.7835 - val_accuracy: 0.8000\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 9.2992e-04 - accuracy: 1.0000 - val_loss: 1.7909 - val_accuracy: 0.8000\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.7338 - val_accuracy: 0.8000\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 2.5222 - val_accuracy: 0.6000\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.5035 - val_accuracy: 0.6000\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.3873e-04 - accuracy: 1.0000 - val_loss: 2.5212 - val_accuracy: 0.6000\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.4823 - val_accuracy: 0.6000\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1327 - accuracy: 0.9412 - val_loss: 1.9538 - val_accuracy: 0.8000\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 9.2406e-04 - accuracy: 1.0000 - val_loss: 2.0739 - val_accuracy: 0.8000\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.1880 - val_accuracy: 0.8000\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.0336 - val_accuracy: 0.8000\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.3428 - val_accuracy: 0.6000\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 7.5942e-05 - accuracy: 1.0000 - val_loss: 2.3632 - val_accuracy: 0.6000\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.6108 - val_accuracy: 0.6000\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.3345e-04 - accuracy: 1.0000 - val_loss: 2.6153 - val_accuracy: 0.6000\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 3.2447 - val_accuracy: 0.6000\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.3499 - val_accuracy: 0.6000\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.3173e-04 - accuracy: 1.0000 - val_loss: 3.5459 - val_accuracy: 0.6000\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.6276e-05 - accuracy: 1.0000 - val_loss: 3.5699 - val_accuracy: 0.6000\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.9119e-05 - accuracy: 1.0000 - val_loss: 3.6003 - val_accuracy: 0.6000\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1002 - accuracy: 0.9412 - val_loss: 2.9951 - val_accuracy: 0.6000\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.5828 - val_accuracy: 0.6000\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 6.3530e-06 - accuracy: 1.0000 - val_loss: 2.5799 - val_accuracy: 0.6000\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.4998 - val_accuracy: 0.8000\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1545 - accuracy: 0.9412 - val_loss: 2.1208 - val_accuracy: 0.6000\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 7.9940e-07 - accuracy: 1.0000 - val_loss: 2.1213 - val_accuracy: 0.6000\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.1984e-04 - accuracy: 1.0000 - val_loss: 2.1396 - val_accuracy: 0.8000\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.8105e-05 - accuracy: 1.0000 - val_loss: 2.1466 - val_accuracy: 0.8000\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 8.8073e-06 - accuracy: 1.0000 - val_loss: 2.1514 - val_accuracy: 0.8000\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.1938e-04 - accuracy: 1.0000 - val_loss: 2.2612 - val_accuracy: 0.6000\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.2578e-04 - accuracy: 1.0000 - val_loss: 2.2584 - val_accuracy: 0.6000\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.3291 - val_accuracy: 0.8000\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.1189e-06 - accuracy: 1.0000 - val_loss: 2.3301 - val_accuracy: 0.8000\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 4.4395e-05 - accuracy: 1.0000 - val_loss: 2.3636 - val_accuracy: 0.8000\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.0503e-06 - accuracy: 1.0000 - val_loss: 2.3652 - val_accuracy: 0.8000\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.2264e-05 - accuracy: 1.0000 - val_loss: 2.3984 - val_accuracy: 0.8000\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 8.0450e-05 - accuracy: 1.0000 - val_loss: 2.3198 - val_accuracy: 0.8000\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.9473e-04 - accuracy: 1.0000 - val_loss: 2.3270 - val_accuracy: 0.8000\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.8512e-06 - accuracy: 1.0000 - val_loss: 2.3277 - val_accuracy: 0.8000\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 9.1379e-04 - accuracy: 1.0000 - val_loss: 2.2984 - val_accuracy: 0.8000\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.0821e-04 - accuracy: 1.0000 - val_loss: 2.3757 - val_accuracy: 0.8000\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.4675e-05 - accuracy: 1.0000 - val_loss: 2.3697 - val_accuracy: 0.8000\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.7262e-06 - accuracy: 1.0000 - val_loss: 2.3705 - val_accuracy: 0.8000\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.1224e-05 - accuracy: 1.0000 - val_loss: 2.3833 - val_accuracy: 0.8000\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.4037 - val_accuracy: 0.8000\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0603 - accuracy: 0.9412 - val_loss: 2.5902 - val_accuracy: 0.8000\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.6488 - val_accuracy: 0.8000\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.4052e-06 - accuracy: 1.0000 - val_loss: 2.6482 - val_accuracy: 0.8000\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 5.2440e-04 - accuracy: 1.0000 - val_loss: 2.7595 - val_accuracy: 0.8000\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 6.6116e-05 - accuracy: 1.0000 - val_loss: 2.7966 - val_accuracy: 0.8000\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.0826e-05 - accuracy: 1.0000 - val_loss: 2.7828 - val_accuracy: 0.8000\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 2.6197 - val_accuracy: 0.8000\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.7280e-04 - accuracy: 1.0000 - val_loss: 2.5727 - val_accuracy: 0.8000\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 5.2071e-05 - accuracy: 1.0000 - val_loss: 2.5832 - val_accuracy: 0.8000\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 9.3405e-04 - accuracy: 1.0000 - val_loss: 2.8862 - val_accuracy: 0.8000\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.5414e-04 - accuracy: 1.0000 - val_loss: 3.0555 - val_accuracy: 0.8000\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 4.8634e-04 - accuracy: 1.0000 - val_loss: 3.0642 - val_accuracy: 0.8000\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 6.6617e-07 - accuracy: 1.0000 - val_loss: 3.0634 - val_accuracy: 0.8000\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 3.0627 - val_accuracy: 0.8000\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1026 - accuracy: 0.9412 - val_loss: 2.8227 - val_accuracy: 0.8000\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.5586e-05 - accuracy: 1.0000 - val_loss: 2.8390 - val_accuracy: 0.8000\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 3.9284e-05 - accuracy: 1.0000 - val_loss: 2.7944 - val_accuracy: 0.8000\n",
      "INFO:tensorflow:Assets written to: cahtbotmodel4.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cahtbotmodel4.model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text preprocessing process is complete.\n"
     ]
    }
   ],
   "source": [
    "training = []\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "for document in documents:\n",
    "    bag = []\n",
    "    word_patterns = document[0]\n",
    "    word_patterns = [lemmatizer.lemmatize(word.lower()) for word in word_patterns]\n",
    "    for word in words:\n",
    "        bag.append(1) if word in word_patterns else bag.append(0)\n",
    "\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(document[1])] = 1\n",
    "    training.append([bag, output_row])\n",
    "\n",
    "random.shuffle(training)\n",
    "training = np.array(training, dtype=object)\n",
    "\n",
    "train_x = list(training[:,0])\n",
    "train_y = list(training[:,1])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
    "\n",
    "rmsprop = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(np.array(train_x), np.array(train_y), epochs=100, batch_size=5, validation_split=0.2, verbose=1)\n",
    "model.save('cahtbotmodel4.model', hist)\n",
    "print(\"The text preprocessing process is complete.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009d7f05-1a39-4b7b-ab56-ec516f1d7534",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
